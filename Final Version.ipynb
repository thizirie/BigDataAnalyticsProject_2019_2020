{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import scipy as sp\n",
    "import sklearn as sk # data mining tools\n",
    "import matplotlib.pylab as plt # plotting\n",
    "import seaborn as sns # advanced plotting\n",
    "import ast\n",
    "import collections\n",
    "import re \n",
    "import six\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "pd.options.display.max_colwidth = 100\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('ted_main.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filling Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['speaker_occupation'].fillna(df['speaker_occupation'].mode()[0], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Funny Factor and Popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['comm_sc'] = ( df['comments'] - df['comments'].min() ) / ( df['comments'].max() - df['comments'].min() )\n",
    "df['views_sc'] = ( df['views'] - df['views'].min() ) / ( df['views'].max() - df['views'].min() )\n",
    "df['ratings'] = df['ratings'].apply(lambda x: ast.literal_eval(x))\n",
    "df['tags'] = df['tags'].apply(lambda x: ast.literal_eval(x))\n",
    "df['ratings_count'] = 0\n",
    "\n",
    "for i in range(df.shape[0]):\n",
    "    cnt = 0\n",
    "    for rev in range(0, 14):\n",
    "        cnt = cnt + df['ratings'][i][rev].get('count')\n",
    "    df.loc[(i, 'ratings_count')] = cnt\n",
    "    \n",
    "df['ratings_nbr_sc'] = ( df['ratings_count'] - df['ratings_count'].min() ) / ( df['ratings_count'].max() - df['ratings_count'].min() )\n",
    "df['popularity'] = ( df['views_sc'] + df['comm_sc'] + df['ratings_nbr_sc']) / 3\n",
    "df.drop(['comm_sc','views_sc', 'ratings_nbr_sc'], axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trans = pd.read_csv('transcripts.csv')\n",
    "df_trans['laughter'] = 0\n",
    "# Drop duplicates \n",
    "df_trans.drop_duplicates(keep = False,inplace = True)\n",
    "# re_assign index after droping dupliacte rows \n",
    "df_trans.index = range(0,len(df_trans))\n",
    "\n",
    "#iterate in each row and sum frequency of the word 'Laughter'\n",
    "#append the value to 'laughter' col\n",
    "\n",
    "word = 'Laughter'\n",
    "for i in range(0,df_trans.shape[0]):\n",
    "    count = 0\n",
    "    input_tedtalk = df_trans['transcript'][i] \n",
    "    count = count + sum(1 for _ in re.finditer(r'\\b%s\\b' % re.escape(word), input_tedtalk))\n",
    "    df_trans.loc[(i,'laughter')] = count\n",
    "\n",
    "# frequency of laughter \n",
    "df_trans['Scaled_laugh']  = (df_trans['laughter'] - df_trans['laughter'].min()) / (df_trans['laughter'].max() - df_trans['laughter'].min())\n",
    "# Merge the two datafarmes on column = url (inner join) and return a DF\n",
    "df = pd.merge(df,df_trans, on = 'url', how='outer')\n",
    "df.update(df[['Scaled_laugh','laughter']].fillna(0))\n",
    "df['funny_factor'] = df['Scaled_laugh']\n",
    "df.drop(['Scaled_laugh','laughter'], axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['year'] = df['published_date'].apply(lambda x: pd.to_datetime(x, unit='s').year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunkIt(seq, num):\n",
    "    avg = len(seq) / float(num)\n",
    "    out = []\n",
    "    last = 0.0\n",
    "\n",
    "    while last < len(seq):\n",
    "        out.append(seq[int(last):int(last + avg)])\n",
    "        last += avg\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making Popularity classified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['popularity_class'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#_0 = chunkIt(df.popularity.sort_values().tolist(), 3)[0][0]\n",
    "_1 = chunkIt(df.popularity.sort_values().tolist(), 3)[0][-1]\n",
    "_2 = chunkIt(df.popularity.sort_values().tolist(), 3)[1][0]\n",
    "_3 = chunkIt(df.popularity.sort_values().tolist(), 3)[1][-1]\n",
    "_4 = chunkIt(df.popularity.sort_values().tolist(), 3)[2][0]\n",
    "#_5 = chunkIt(df.popularity.sort_values().tolist(), 3)[1][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[((df.popularity >= 0)&(df.popularity <= _1)), 'popularity_class'] = 0\n",
    "df.loc[((df.popularity >= _2)&(df.popularity <= _3)), 'popularity_class'] = 1\n",
    "df.loc[((df.popularity >= _4)&(df.popularity <= 1)), 'popularity_class'] = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Occupations (Dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Literature'] = 0\n",
    "df['Art'] = 0\n",
    "df['Economy_Politics'] = 0\n",
    "df['Medicine'] = 0\n",
    "df['Academy'] = 0\n",
    "df['Engineering_Science'] = 0\n",
    "df['Other_Occupations'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[(df.speaker_occupation == \"Writer\"), 'Literature'] = 1\n",
    "df.loc[(df.speaker_occupation == \"Journalist\"), 'Literature'] = 1\n",
    "df.loc[(df.speaker_occupation == \"Author\"), 'Literature'] = 1\n",
    "df.loc[(df.speaker_occupation == \"Philosopher\"), 'Literature'] = 1\n",
    "df.loc[(df.speaker_occupation == \"Historian\"), 'Literature'] = 1\n",
    "df.loc[(df.speaker_occupation == \"Poet\"), 'Literature'] = 1\n",
    "df.loc[(df.speaker_occupation == \"Novelist\"), 'Literature'] = 1\n",
    "df.loc[(df.speaker_occupation == \"Reporter\"), 'Literature'] = 1\n",
    "df.loc[(df.speaker_occupation == \"Writer, activist\"), 'Literature'] = 1\n",
    "df.loc[(df.speaker_occupation == \"Performance poet, multimedia artist\"), 'Literature'] = 1\n",
    "df.loc[(df.speaker_occupation == \"Science writer\"), 'Literature'] = 1\n",
    "\n",
    "df.loc[(df.speaker_occupation == \"Designer\"), 'Art'] = 1\n",
    "df.loc[(df.speaker_occupation == \"Chef\"), 'Art'] = 1\n",
    "df.loc[(df.speaker_occupation == \"Violinist\"), 'Art'] = 1\n",
    "df.loc[(df.speaker_occupation == \"Producer\"), 'Art'] = 1\n",
    "df.loc[(df.speaker_occupation == \"Cartoonist\"), 'Art'] = 1\n",
    "df.loc[(df.speaker_occupation == \"Performance poet, multimedia artist\"), 'Art'] = 1\n",
    "df.loc[(df.speaker_occupation == \"Photojournalist\"), 'Art'] = 1\n",
    "df.loc[(df.speaker_occupation == \"Singer-songwriter\"), 'Art'] = 1\n",
    "df.loc[(df.speaker_occupation == \"Artist\"), 'Art'] = 1\n",
    "df.loc[(df.speaker_occupation == \"Architect\"), 'Art'] = 1\n",
    "df.loc[(df.speaker_occupation == \"Photographer\"), 'Art'] = 1\n",
    "df.loc[(df.speaker_occupation == \"Filmmaker\"), 'Art'] = 1\n",
    "df.loc[(df.speaker_occupation == \"Musician\"), 'Art'] = 1\n",
    "df.loc[(df.speaker_occupation == \"Singer/songwriter\"), 'Art'] = 1\n",
    "df.loc[(df.speaker_occupation == \"Graphic designer\"), 'Art'] = 1\n",
    "df.loc[(df.speaker_occupation == \"Techno-illusionist\"), 'Art'] = 1\n",
    "df.loc[(df.speaker_occupation == \"Comedian\"), 'Art'] = 1\n",
    "df.loc[(df.speaker_occupation == \"Musician, activist\"), 'Art'] = 1\n",
    "df.loc[(df.speaker_occupation == \"Sculptor\"), 'Art'] = 1\n",
    "\n",
    "df.loc[(df.speaker_occupation == \"Entrepreneur\"), 'Economy_Politics'] = 1\n",
    "df.loc[(df.speaker_occupation == \"Environmentalist, futurist\"), 'Economy_Politics'] = 1\n",
    "df.loc[(df.speaker_occupation == \"Investor and advocate for moral leadership\"), 'Economy_Politics'] = 1\n",
    "df.loc[(df.speaker_occupation == \"Musician, activist\"), 'Economy_Politics'] = 1\n",
    "df.loc[(df.speaker_occupation == \"Economist\"), 'Economy_Politics'] = 1\n",
    "df.loc[(df.speaker_occupation == \"Activist\"), 'Economy_Politics'] = 1\n",
    "df.loc[(df.speaker_occupation == \"Philanthropist\"), 'Economy_Politics'] = 1\n",
    "df.loc[(df.speaker_occupation == \"Behavioral economist\"), 'Economy_Politics'] = 1\n",
    "df.loc[(df.speaker_occupation == \"Writer, activist\"), 'Economy_Politics'] = 1\n",
    "df.loc[(df.speaker_occupation == \"Climate advocate\"), 'Economy_Politics'] = 1\n",
    "df.loc[(df.speaker_occupation == \"Legal activist\"), 'Economy_Politics'] = 1\n",
    "df.loc[(df.speaker_occupation == \"Futurist\"), 'Economy_Politics'] = 1\n",
    "df.loc[(df.speaker_occupation == \"Social entrepreneur\"), 'Economy_Politics'] = 1\n",
    "\n",
    "df.loc[(df.speaker_occupation == \"Psychologist\"), 'Medicine'] = 1\n",
    "df.loc[(df.speaker_occupation == \"Neuroscientist\"), 'Medicine'] = 1\n",
    "df.loc[(df.speaker_occupation == \"Global health expert; data visionary\"), 'Medicine'] = 1\n",
    "df.loc[(df.speaker_occupation == \"Social psychologist\"), 'Medicine'] = 1\n",
    "df.loc[(df.speaker_occupation == \"Surgeon\"), 'Medicine'] = 1\n",
    "df.loc[(df.speaker_occupation == \"Physician\"), 'Medicine'] = 1\n",
    "\n",
    "df.loc[(df.speaker_occupation == \"Educator\"), 'Academy'] = 1\n",
    "\n",
    "df.loc[(df.speaker_occupation == \"Roboticist\"), 'Engineering_Science'] = 1\n",
    "df.loc[(df.speaker_occupation == \"Biologist\"), 'Engineering_Science'] = 1\n",
    "df.loc[(df.speaker_occupation == \"Physicist\"), 'Engineering_Science'] = 1\n",
    "df.loc[(df.speaker_occupation == \"Marine biologist\"), 'Engineering_Science'] = 1\n",
    "df.loc[(df.speaker_occupation == \"Technologist\"), 'Engineering_Science'] = 1\n",
    "df.loc[(df.speaker_occupation == \"Global health expert; data visionary\"), 'Engineering_Science'] = 1\n",
    "df.loc[(df.speaker_occupation == \"Astronomer\"), 'Engineering_Science'] = 1\n",
    "df.loc[(df.speaker_occupation == \"Oceanographer\"), 'Engineering_Science'] = 1\n",
    "df.loc[(df.speaker_occupation == \"Engineer\"), 'Engineering_Science'] = 1\n",
    "df.loc[(df.speaker_occupation == \"Computer scientist\"), 'Engineering_Science'] = 1\n",
    "df.loc[(df.speaker_occupation == \"Inventor\"), 'Engineering_Science'] = 1\n",
    "df.loc[(df.speaker_occupation == \"Futurist\"), 'Engineering_Science'] = 1\n",
    "df.loc[(df.speaker_occupation == \"Mathematician\"), 'Engineering_Science'] = 1\n",
    "df.loc[(df.speaker_occupation == \"Astrophysicist\"), 'Engineering_Science'] = 1\n",
    "df.loc[(df.speaker_occupation == \"Evolutionary biologist\"), 'Engineering_Science'] = 1\n",
    "df.loc[(df.speaker_occupation == \"Sound consultant\"), 'Engineering_Science'] = 1\n",
    "df.loc[(df.speaker_occupation == \"Game designer\"), 'Engineering_Science'] = 1\n",
    "df.loc[(df.speaker_occupation == \"Chemist\"), 'Engineering_Science'] = 1\n",
    "df.loc[(df.speaker_occupation == \"Social Media Theorist\"), 'Engineering_Science'] = 1\n",
    "df.loc[(df.speaker_occupation == \"Data scientist\"), 'Engineering_Science'] = 1\n",
    "df.loc[(df.speaker_occupation == \"Tech visionary\"), 'Engineering_Science'] = 1\n",
    "df.loc[(df.speaker_occupation == \"Paleontologist\"), 'Engineering_Science'] = 1\n",
    "df.loc[(df.speaker_occupation == \"Researcher\"), 'Engineering_Science'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "occ_df = df[((df.Literature != 1) & (df.Art != 1)& (df.Economy_Politics != 1)\\\n",
    "                      & (df.Medicine != 1)& (df.Academy != 1)& (df.Engineering_Science != 1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = {\"Author\":\"Literature\",\"Actor\":\"Art\", \"researcher\":\"Engineering_Science\",\n",
    "             \"Historian\":\"Literature\", \"Philosopher\": \"Literature\", \"Activist\":\"Economy_Politics\" , \"Robotics\":\"Engineering_Science\",\n",
    "             \"engineer\":\"Engineering_Science\", \"composer\":\"Art\", \"Pianist\":\"Art\", \"Marketing\":\"Economy_Politics\",\n",
    "             \"Public\":\"Economy_Politics\", \"fund\":\"Economy_Politics\" , \"psycho\":\"Medicine\", \"logist\":\"Engineering_Science\",\n",
    "             \"computer\":\"Engineering_Science\", \"writer\":\"Literature\", \"expert\":\"Engineering_Science\", \"Industrial\":\"Engineering_Science\",\n",
    "             \"artist\":\"Art\",\"scientist\":\"Engineering_Science\", \"founder\":\"Economy_Politics\", \"specialist\":'Engineering_Science',\"music\":\"Art\",\n",
    "             \"design\":\"Art\", \"physicist\":\"Engineering_Science\", \"educat\":\"Academy\", \"Mayor\":\"Economy_Politics\", \"President\":\"Economy_Politics\",\n",
    "             \"art\":\"Art\", \"bio\":\"Engineering_Science\", \"tech\":\"Engineering_Science\", \"professor\":\"Academy\", \"math\":\"Engineering_Science\",\n",
    "             \"cyber\":\"Engineering_Science\", \"capital\":\"Economy_Politics\", \"digit\":\"Engineering_Science\", \"entrepreneur\":\"Economy_Politics\",\n",
    "             \"religi\":\"Economy_Politics\", \"genetic\":\"Engineering_Science\", \"futur\":\"Economy_Politics\", \"explorer\":\"Economy_Politics\", \n",
    "             \"journ\":\"Literature\", \"law\":\"Economy_Politics\", \"Global\":\"Economy_Politics\", \"advocate\":\"Economy_Politics\", \"company\":\"Economy_Politics\",\n",
    "             \"story\":\"Literature\", \"novel\":\"Literature\", \"band\":\"Art\", \"photo\":\"Art\", \"arch\":\"Art\", \"chem\":\"Engineering_Science\", \"care\":\"Medicine\",\n",
    "             \"visual\":\"Art\", \"innov\":\"Engineering_Science\", \"analy\":\"Engineering_Science\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for keys in dictionary.keys():\n",
    "    for index, row in occ_df.iterrows():\n",
    "        myString = occ_df['speaker_occupation'][index].lower()\n",
    "        if (myString.find(keys.lower()) > -1):\n",
    "            (df.loc[(index, dictionary[keys])]) = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Other_Occupations'][((df.Literature != 1) & (df.Art != 1)& (df.Economy_Politics != 1)\\\n",
    "                      & (df.Medicine != 1)& (df.Academy != 1)& (df.Engineering_Science != 1))] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Speaker and Tags Trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker_trends_df = pd.read_csv(\"speakers_interest_over_time.csv\")\n",
    "tag_trends_df = pd.read_csv(\"tags_interest_over_time.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_value(name):\n",
    "    years_list = ['2006', '2007','2008','2009','2010','2011','2012','2013','2014','2015','2016','2017']\n",
    "    result = 0\n",
    "    row = speaker_trends_df[speaker_trends_df.main_speaker == name]\n",
    "    for year in years_list:\n",
    "        result = result + row[year].values[0]\n",
    "    return float(result)/len(years_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['speaker_trend'] = df['main_speaker'].apply(lambda x: get_value(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_value_list(tagsList):\n",
    "    years_list = ['2006', '2007','2008','2009','2010','2011','2012','2013','2014','2015','2016','2017']\n",
    "    total_result = 0\n",
    "    for tag in tagsList:\n",
    "        result = 0\n",
    "        row = tag_trends_df[tag_trends_df.tags == tag]\n",
    "        for year in years_list:\n",
    "            result = result + row[year].values[0]\n",
    "        total_result = total_result + (float(result)/len(years_list))\n",
    "    return float(total_result)/len(tagsList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['tags'] = df['tags'].apply(lambda x: ast.literal_eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tags_trend'] = df['tags'].apply(lambda x: get_value_list(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Weekdays (Dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert a timestamp 'published_date' value into date object then convert the value to the corresponding weekday\n",
    "from datetime import datetime\n",
    "import calendar \n",
    "df['Published_day'] = df['published_date'].apply(lambda x: datetime.fromtimestamp(x).strftime('%m/%d/%Y'))\n",
    "df['Pweek_day']= (pd.to_datetime(df['Published_day'])).apply(lambda d: calendar.day_name[d.weekday()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating new columns\n",
    "df['Monday']=0\n",
    "df['Tuesday']=0\n",
    "df['Wednesday']=0\n",
    "df['Thursday']=0\n",
    "df['Friday']=0\n",
    "df['Saturday']=0\n",
    "df['Sunday']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting 1 only in the right cell\n",
    "df.loc[df.Pweek_day == 'Monday', 'Monday'] = 1\n",
    "df.loc[df.Pweek_day == 'Tuesday', 'Tuesday'] = 1\n",
    "df.loc[df.Pweek_day == 'Wednesday', 'Wednesday'] = 1\n",
    "df.loc[df.Pweek_day == 'Thursday', 'Thursday'] = 1\n",
    "df.loc[df.Pweek_day == 'Friday', 'Friday'] = 1\n",
    "df.loc[df.Pweek_day == 'Saturday', 'Saturday'] = 1\n",
    "df.loc[df.Pweek_day == 'Sunday', 'Sunday'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop Pweek_day column\n",
    "df.drop(['Pweek_day'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Events (Dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values, counts = np.unique(df['event'], return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['TEDx'] = 0\n",
    "df['TED'] = 0\n",
    "df['TED_Global'] = 0\n",
    "df['TED_Other'] = 0\n",
    "df['Non_TED_University'] = 0\n",
    "df['Non_TED_Other'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[(df.event == \"TED1984\"), 'TED'] = 1\n",
    "df.loc[(df.event == \"TED1990\"), 'TED'] = 1\n",
    "df.loc[(df.event == \"TED1994\"), 'TED'] = 1\n",
    "df.loc[(df.event == \"TED1998\"), 'TED'] = 1\n",
    "df.loc[(df.event == \"TED2001\"), 'TED'] = 1\n",
    "df.loc[(df.event == \"TED2002\"), 'TED'] = 1\n",
    "df.loc[(df.event == \"TED2003\"), 'TED'] = 1\n",
    "df.loc[(df.event == \"TED2004\"), 'TED'] = 1\n",
    "df.loc[(df.event == \"TED2005\"), 'TED'] = 1\n",
    "df.loc[(df.event == \"TED2006\"), 'TED'] = 1\n",
    "df.loc[(df.event == \"TED2007\"), 'TED'] = 1\n",
    "df.loc[(df.event == \"TED2008\"), 'TED'] = 1\n",
    "df.loc[(df.event == \"TED2009\"), 'TED'] = 1\n",
    "df.loc[(df.event == \"TED2010\"), 'TED'] = 1\n",
    "df.loc[(df.event == \"TED2011\"), 'TED'] = 1\n",
    "df.loc[(df.event == \"TED2012\"), 'TED'] = 1\n",
    "df.loc[(df.event == \"TED2012\"), 'TED'] = 1\n",
    "df.loc[(df.event == \"TED2013\"), 'TED'] = 1\n",
    "df.loc[(df.event == \"TED2014\"), 'TED'] = 1\n",
    "df.loc[(df.event == \"TED2015\"), 'TED'] = 1\n",
    "df.loc[(df.event == \"TED2016\"), 'TED'] = 1\n",
    "df.loc[(df.event == \"TED2017\"), 'TED'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oth_df = df[(df.TED != 1)]\n",
    "values_, counts_ = np.unique(oth_df['event'], return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dico = {\"TEDx\":\"TEDx\",\"TEDGlobal\":\"TED_Global\", \"TED D\":\"TED_Other\", \"TED F\":\"TED_Other\",\\\n",
    "        \"TED P\":\"TED_Other\", \"TED R\":\"TED_Other\", \"TED S\":\"TED_Other\", \"TED T\":\"TED_Other\", \"TED i\":\"TED_Other\",\\\n",
    "        \"TEDD\":\"TED_Other\", \"TEDE\":\"TED_Other\", \"TEDF\":\"TED_Other\", \"TEDG\":\"TED_Other\", \"TEDH\":\"TED_Other\", \\\n",
    "        \"TEDI\":\"TED_Other\", \"TEDJ\":\"TED_Other\", \"TEDK\":\"TED_Other\", \"TEDL\":\"TED_Other\", \"TEDM\":\"TED_Other\", \\\n",
    "        \"TEDN\":\"TED_Other\", \"TEDO\":\"TED_Other\", \"TEDP\":\"TED_Other\", \"TEDQ\":\"TED_Other\", \"TEDR\":\"TED_Other\", \\\n",
    "        \"TEDS\":\"TED_Other\", \"TEDT\":\"TED_Other\", \"TEDU\":\"TED_Other\", \"TEDV\":\"TED_Other\", \"TEDW\":\"TED_Other\", \\\n",
    "        \"TEDY\":\"TED_Other\", \"TEDZ\":\"TED_Other\", \"TED-E\":\"TED_Other\", \\\n",
    "        \" University\":\"Non_TED_University\",\\\n",
    "       \"TED@\":\"TED\"\\\n",
    "       }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for keys in dico.keys():\n",
    "    for index, row in oth_df.iterrows():\n",
    "        myString = oth_df['event'][index].lower()\n",
    "        if (myString.find(keys.lower()) > -1):\n",
    "            (df.loc[(index, dico[keys])]) = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Non_TED_Other'][((df.TEDx != 1) & (df.TED != 1)& (df.TED_Global != 1)\\\n",
    "                     & (df.TED_Other != 1)& (df.Non_TED_University != 1))] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(df.shape[0]):\n",
    "    if (df['TED_Global'][i] == 1 & df['TED_Other'][i] == 1):\n",
    "        df['TED_Other'][i] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Question and How columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['question']=0\n",
    "for i in range (0,len(df)):\n",
    "    if ((\"?\") in df.loc[(i,'title')]):\n",
    "        df.loc[(i,'question')] = 1\n",
    "    else:\n",
    "        df.loc[(i,'question')] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['how']=0\n",
    "for i in range (0,len(df)):\n",
    "    if ((\"how\") in df.loc[(i,'title')]):\n",
    "        df.loc[(i,'how')] = 1\n",
    "    else:\n",
    "        df.loc[(i,'how')] = 0\n",
    "for i in range (0,len(df)):\n",
    "    if ((\"How\") in df.loc[(i,'title')]):\n",
    "        df.loc[(i,'how')] = 1\n",
    "    else:\n",
    "        df.loc[(i,'how')] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, precision_score\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes = ['duration', 'num_speaker', 'Literature', 'Art' ,'Economy_Politics', 'Medicine',\n",
    "             'Academy', 'Engineering_Science', 'Other_Occupations',\n",
    "             'speaker_trend', 'tags_trend', 'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday','Sunday',\n",
    "              'funny_factor', 'TEDx', 'TED', 'TED_Global', 'TED_Other', 'Non_TED_University', 'Non_TED_Other', 'how', 'question']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[attributes].values\n",
    "y = df['popularity_class']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.5, \n",
    "                                                    random_state=100\n",
    "                                                    ,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(criterion='entropy', max_depth=5, \n",
    "                             min_samples_split=60, min_samples_leaf=5)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col, imp in zip(attributes, clf.feature_importances_):\n",
    "    print(col, imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydotplus\n",
    "from sklearn import tree\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PATH'] += os.pathsep + 'C:/Users/Pouria/Anaconda3/pkgs/graphviz-2.38-hfd603c8_2/Library/bin/graphviz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_data = tree.export_graphviz(clf, out_file=None,  \n",
    "                                feature_names=attributes,   \n",
    "                                filled=True, rounded=True,  \n",
    "                                special_characters=True,max_depth=3)  \n",
    "graph = pydotplus.graph_from_dot_data(dot_data)  \n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = clf.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Precision %s' % precision_score(y_train, y_train_pred, average='micro'))\n",
    "print('Accuracy %s' % accuracy_score(y_train, y_train_pred))\n",
    "print('F1-score %s' % f1_score(y_train, y_train_pred, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Precision %s' % precision_score(y_test, y_test_pred, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.9f} (std: {1:.9f})\".format(\n",
    "                  results['mean_test_score'][candidate],\n",
    "                  results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_list = {'criterion': ['gini','entropy'],\n",
    "              'max_depth': [None] + list(np.arange(2, 6)),\n",
    "              'min_samples_split': [2, 5, 10, 20, 30, 40, 50, 60, 70],\n",
    "              'min_samples_leaf': [1, 5, 10, 20, 30, 40, 50, 60, 70]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(clf, param_grid=param_list)\n",
    "grid_search.fit(X_train, y_train)\n",
    "clf = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report(grid_search.cv_results_, n_top=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_cross_scores = cross_val_score(clf, X_test, y_test, cv=10, scoring='precision_micro')\n",
    "print('Precision: %0.4f (+/- %0.2f)' % (precision_cross_scores.mean(), precision_cross_scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Predicted Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['predicted_class'] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = 0\n",
    "for i, v in y_test.items():\n",
    "    df.loc[(i, 'predicted_class')] = y_test_pred[j]\n",
    "    j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['popularity_class','predicted_class']].sample(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting one sample talk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = 1468\n",
    "df_sample_class_2 = df.iloc[sample]\n",
    "X_class_2 = df_sample_class_2[attributes].values\n",
    "y_class_2 = df_sample_class_2['popularity_class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_class_2 = X_class_2.reshape(X_class_2.shape[0],1).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_sample_pred = clf.predict(X_class_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_sample_pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[sample]['popularity_class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Actual class for talk %d is %d, and predicted class is %d\"% (sample, df.iloc[sample]['popularity_class'], y_sample_pred[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
